# 高级 AI Agent 架构设计指南

本仓库采用多维思考与 Agent 协议，旨在构建高可靠、可扩展的 AI 智能体应用。以下是针对复杂业务场景推荐的三大核心架构模式及其补充进阶知识。

---

## 核心架构模式

### 1. 专家智能体模式 (Hierarchical/Sub-Agent Pattern)
**核心思路**：在 `Switch/Case` 分发逻辑之后，进入一个专门针对该业务领域优化的 AI 环节，而非死板的固定脚本。

*   **分拣员 (Router)**：负责意图识别，例如判断用户是想做“任务管理”还是“知识库查询”。
*   **专家员 (Worker Agent)**：进入对应分支（如 `handleTaskManager`）后，启动专属 AI。
    *   **专属工具箱**：该 AI 拥有特定领域的工具（如 `search_user`, `query_calendar`, `get_priority_rules`）。
    *   **局部循环**：它在特定业务逻辑内进行多轮交互（如 Slot Filling），直到完成任务。
*   **价值**：实现**职责分离**。Router 无需感知业务细节，系统扩展只需增加新的专家模块。

### 2. 领航员-执行员模式 (Plan-and-Execute)
**核心思路**：AI 首先制定详细的任务计划（Plan），然后由代码框架按步骤驱动执行（Execute）。

*   **领航员 (Planner)**：分析复杂或跨系统的需求，拆解为原子步骤。
    *   *示例需求*：“查一下昨日北京分公司销售额，若低于一万，发飞书提醒给王总。”
    *   *AI 计划*：
        1. 调用 `query_sales_data(city="北京", date="yesterday")`。
        2. 代码逻辑判断：`if result < 10000`。
        3. 调用 `send_feishu_message(target="王总", content="...")`。
*   **执行员 (Executor)**：代码严格按照计划序列调度工具，并处理每一步的状态回传。
*   **价值**：处理**长链条、逻辑依赖强**的任务，提高复杂任务的成功率。

### 3. 反思与校验模式 (Reflection / Critique Pattern)
**核心思路**：在业务逻辑执行完成后，引入一个独立的 AI “检查员”对结果进行二次质量把控。

*   **流程**：`Router -> 业务执行 -> AI 检查员 -> 最终输出`。
*   **AI 检查员职责**：
    *   检查生成内容的质量（如错别字、语气正式度、事实正确性）。
    *   **打回机制**：若检查不合格，要求执行层重写或修正。
*   **价值**：极大地降低 AI 生成内容的“幻觉”风险，确保企业级交付的**确定性**。

---

## 补充进阶建议 (学习重点)

为了进一步提升 AI 应用的专业度，建议关注以下三个维度：

### A. 动态上下文压缩 (Context Management)
随着对话轮数增加，Token 消耗和模型注意力分散是痛点。
*   **策略**：只给专家 Agent 传递它需要的历史上下文，并在切换专家时进行“小结（Summary）”传递，保持上下文的精简。

### B. 人机协同（Human-in-the-Loop）
对于高价值或敏感操作（如：发全员公告、支付转账），不要让 AI 闭环执行。
*   **实现**：在工具调用链中增加一个 `WAIT_USER_CONFIRM` 状态。AI 生成预览，等待用户在飞书卡片上点击“确认”后，代码再调用真实的 API。

### C. 错误自愈（Self-Correction）
当工具调用失败（如 API 报错）时，直接把错误丢还给 AI。
*   **策略**：给 AI 返回具体的错误描述（如：“参数 A 格式错误”）。高级模型通常能根据错误信息，自动修正参数并重新发起 `tool_calls`。

---

## 结语
架构设计的本质是在**灵活性（AI）**与**确定性（Code）**之间寻找平衡。对于 `agent-modal` 项目，建议先从 **专家模式** 入手，将飞书各个 API 模块化，构建你的“数字员工”方阵。
